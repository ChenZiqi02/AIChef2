from langchain_huggingface import HuggingFaceEmbeddings
from langchain_chroma import Chroma
from core.config import DB_PATH_V3, EMBEDDING_MODEL_NAME, COLLECTION_NAME
import torch

class VectorDBManager:
    """
    å•ä¾‹æ¨¡å¼ç®¡ç†æ•°æ®åº“è¿æ¥ï¼Œé˜²æ­¢é‡å¤åŠ è½½æ¨¡å‹å¯¼è‡´å†…å­˜çˆ†ç‚¸
    """
    _instance = None
    _vector_store = None

    @classmethod
    def get_vector_store(cls):
        if cls._vector_store is None:
            print(f"ğŸ”„ [Retriever] æ­£åœ¨åˆå§‹åŒ–å‘é‡åº“: {DB_PATH_V3}")
            try:
                if torch.backends.mps.is_available():
                    device = "mps"
                elif torch.cuda.is_available():
                    device = "cuda"
                else:
                    device = "cpu"
                embeddings = HuggingFaceEmbeddings(
                    model_name=EMBEDDING_MODEL_NAME,
                    model_kwargs={'device': device},
                    encode_kwargs={'normalize_embeddings': True}
                )
                # âš ï¸ collection_name å¿…é¡»å’Œä½  ingest å…¥åº“æ—¶çš„ä¸€è‡´ï¼
                # ä¹‹å‰æˆ‘ä»¬ç”¨çš„æ˜¯ "recipe_collection_v3"
                cls._vector_store = Chroma(
                    collection_name=COLLECTION_NAME, 
                    embedding_function=embeddings,
                    persist_directory=DB_PATH_V3
                )
                print("âœ… [Retriever] å‘é‡åº“åŠ è½½å®Œæˆ")
            except Exception as e:
                print(f"âŒ [Retriever] æ•°æ®åº“åŠ è½½å¤±è´¥: {e}")
                return None
        return cls._vector_store


def retrieve_docs(query: str, top_k: int = 4, score_threshold: float = 1.0, preferences: dict = None):
    """
    æ£€ç´¢æ ¸å¿ƒå‡½æ•°
    :param preferences: ç”¨æˆ·åå¥½å­—å…¸ï¼Œä¾‹å¦‚ {"dislikes": ["é¦™èœ", "è¾£"]}
    """
    db = VectorDBManager.get_vector_store()
    if not db:
        return []

    # æ‰§è¡Œæ£€ç´¢
    results = db.similarity_search_with_score(query, k=top_k)
    
    # æ ¼å¼åŒ–ç»“æœ
    filtered_results = []
    print(f"ğŸ” [Retriever] æ£€ç´¢åˆ° {len(results)} æ¡ï¼Œé˜ˆå€¼: {score_threshold}")
    
    for doc, score in results:
        print(f"   - {doc.metadata.get('name')} (Score: {score:.4f})")
        # æ¢å¤æ­£å¸¸çš„é˜ˆå€¼è¿‡æ»¤
        if score <= score_threshold:
            filtered_results.append({
                "id": doc.metadata.get('id', ''),          # å»ºè®®åŠ ä¸Š ID
                "name": doc.metadata.get('name', 'æœªçŸ¥'),
                "tags": doc.metadata.get('tags', ''),
                "image": doc.metadata.get('image', ''),
                
                # âœ…ã€æ–°å¢å…³é”®ä¿®æ”¹ã€‘æå–æ­¥éª¤æ•°æ®
                "instructions": doc.metadata.get('instructions', []), 
                
                "content": doc.page_content,
                "score": score
            })
            
    # --- åç½®è¿‡æ»¤ (Post-Retrieval Filtering) based on User Preferences ---
    if preferences:
        final_results = []
        dislikes = preferences.get("dislikes", [])
        allergies = preferences.get("allergies", [])
        
        # å°†ä¸å–œæ¬¢å’Œè¿‡æ•æºåˆå¹¶æ£€æŸ¥
        avoid_list = [x.lower() for x in (dislikes + allergies) if x]
        
        if avoid_list:
            print(f"ğŸ›‘ [Retriever] æ­£åœ¨è¿‡æ»¤ç”¨æˆ·å¿Œå£: {avoid_list}")
            for res in filtered_results:
                # æ£€æŸ¥èœå“åç§°ã€æ ‡ç­¾å’Œå†…å®¹æ˜¯å¦åŒ…å«å¿Œå£è¯
                text_to_check = (res['name'] + str(res['tags']) + res['content']).lower()
                
                is_safe = True
                for word in avoid_list:
                    if word in text_to_check:
                        print(f"   -> å‰”é™¤ '{res['name']}' (åŒ…å«å¿Œå£: {word})")
                        is_safe = False
                        break
                
                if is_safe:
                    final_results.append(res)
            return final_results

    return filtered_results