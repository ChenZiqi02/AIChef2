from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_openai import ChatOpenAI
from core.config import LLM_API_KEY, LLM_BASE_URL, LLM_MODEL_NAME, GEMINI_API_KEY
import re
from google.generativeai.types import HarmCategory, HarmBlockThreshold

# åˆå§‹åŒ–å®¢æˆ·ç«¯ (ä½¿ç”¨ LangChain ç»Ÿä¸€æ¥å£)
llm = None

if GEMINI_API_KEY:
    print(f"âœ… å°è¯•ä½¿ç”¨ Google Gemini API (model: gemini-2.0-flash)")
    llm = ChatGoogleGenerativeAI(
        model="gemini-2.0-flash",
        google_api_key=GEMINI_API_KEY,
        temperature=0.7,
        safety_settings={
            "HARM_CATEGORY_DANGEROUS_CONTENT": "BLOCK_NONE",
            "HARM_CATEGORY_HATE_SPEECH": "BLOCK_NONE",
            "HARM_CATEGORY_HARASSMENT": "BLOCK_NONE",
            "HARM_CATEGORY_SEXUALLY_EXPLICIT": "BLOCK_NONE",
        }
    )
elif LLM_API_KEY:
    print(f"âœ… ä½¿ç”¨ SiliconFlow API (model: {LLM_MODEL_NAME})")
    llm = ChatOpenAI(
        model=LLM_MODEL_NAME,
        api_key=LLM_API_KEY,
        base_url=LLM_BASE_URL,
        temperature=0.4
    )

def safe_invoke(messages):
    """
    ç»Ÿä¸€çš„ LLM è°ƒç”¨å°è£… (Strict Single Model: Gemini 2.0 Flash)
    ç”¨æˆ·æŒ‡ä»¤: ä¸éœ€è¦é™çº§ä¿åº•ï¼Œåªè¦åŸæ¥çš„å¹½é»˜æ•ˆæœã€‚
    """
    if not llm:
        raise Exception("LLM Client not initialized")

    try:
        # ç›´æ¥è°ƒç”¨é¦–é€‰æ¨¡å‹ (å…è®¸é»˜è®¤é‡è¯•)
        return llm.invoke(messages)
    except Exception as e:
        print(f"âŒ [SafeInvoke] Model Failed: {e}")
        # ç›´æ¥æŠ›å‡ºé”™è¯¯ï¼Œä¸åˆ‡æ¢æ¨¡å‹
        raise e

def smart_select_and_comment(query: str, candidates: list):
    """
    æ™ºèƒ½ä¼˜é€‰ Rerank (çµæ´»ç‰ˆ)
    ä¸å†æ­»æ¿è¿‡æ»¤ï¼Œè€Œæ˜¯ä¾§é‡äºâ€œæ¨è + å»ºè®®â€
    """
    if not llm:
        return 0, "API Key æœªé…ç½®ï¼Œé»˜è®¤æ¨èï¼š"
    
    if not candidates:
        return 0, "æ²¡æœ‰å€™é€‰èœè°±ã€‚"

    # 1. æ„å»ºå€™é€‰åˆ—è¡¨
    candidates_str = ""
    for i, doc in enumerate(candidates):
        snippet = doc.get('content', '')[:150].replace('\n', ' ')
        candidates_str += (
            f"é€‰é¡¹[{i}]: {doc.get('name')}\n"
            f"   - æ ‡ç­¾: {doc.get('tags', [])}\n"
            f"   - ç®€ä»‹: {snippet}...\n\n"
        )

    # =====================================================
    # âœ… ä¼˜åŒ–åçš„ Promptï¼šæ›´åƒä¸€ä¸ªæ‡‚å¾—å˜é€šçš„å¤§å¨
    # =====================================================
    system_prompt = """
    ä½ æ˜¯ä¸€ä½èªæ˜ã€æ‡‚å˜é€šçš„ç§å®¶å¤§å¨ã€‚ä½ çš„ä»»åŠ¡æ˜¯ä»ç»™å®šçš„å€™é€‰èœè°±ä¸­ï¼Œä¸ºç”¨æˆ·æ¨è**æœ€åˆé€‚**çš„ä¸€é“ã€‚

    ã€æ¨èé€»è¾‘ã€‘ï¼š
    1. **æ‰¾æœ€å¤§å…¬çº¦æ•°**ï¼šä¼˜å…ˆé€‰æ‹©é£Ÿæã€å£å‘³æœ€æ¥è¿‘ç”¨æˆ·éœ€æ±‚çš„èœã€‚
    2. **çµæ´»å¤„ç†å¿Œå£**ï¼š
       - å¦‚æœç”¨æˆ·è¯´â€œä¸è¦è¾£â€ï¼Œå°½é‡é€‰ä¸è¾£çš„ã€‚
       - **å…³é”®ç‚¹**ï¼šå¦‚æœå€™é€‰é¡¹å…¨éƒ½æœ‰è¾£ï¼Œ**ä¸è¦æ‹’ç»å›ç­”ï¼** è¯·é€‰ä¸€ä¸ªæœ€å®¹æ˜“â€œå»è¾£â€çš„èœï¼ˆæ¯”å¦‚æŠŠè¾£æ¤’æ²¹æ¢æˆé¦™æ²¹ï¼‰ï¼Œå¹¶åœ¨ç†ç”±é‡Œå‘Šè¯‰ç”¨æˆ·æ€ä¹ˆè°ƒæ•´ã€‚
    3. **ä¸ä»…æ˜¯é€‰æ‹©ï¼Œæ›´æ˜¯å»ºè®®**ï¼šæ¨èç†ç”±è¦å‘Šè¯‰ç”¨æˆ·â€œä¸ºä»€ä¹ˆé€‰å®ƒâ€æˆ–è€…â€œæ€ä¹ˆåšæ›´ç¬¦åˆä½ çš„è¦æ±‚â€ã€‚

    ã€è¾“å‡ºæ ¼å¼ã€‘ï¼š
    è¯·ç›´æ¥è¿”å›ä¸€è¡Œï¼šç´¢å¼•æ•°å­— ||| æ¨èç†ç”±
    ï¼ˆä¾‹å¦‚ï¼š1 ||| è™½ç„¶åŸè°±æœ‰è¾£æ¤’ï¼Œä½†è¿™é“èœåªè¦ä¸æ”¾è¾£æ¤’æ²¹ï¼Œä¾ç„¶éå¸¸é²œç¾ï¼Œå¾ˆé€‚åˆæ‚¨ã€‚ï¼‰
    """

    user_prompt = f"""
    ç”¨æˆ·éœ€æ±‚ï¼šã€{query}ã€‘

    å€™é€‰åˆ—è¡¨ï¼š
    {candidates_str}

    è¯·åšå‡ºä½ çš„é€‰æ‹©ï¼š
    """

    try:
        # LangChain è°ƒç”¨
        messages = [
            ("system", system_prompt),
            ("human", user_prompt),
        ]
        
        response_msg = safe_invoke(messages)
        content = response_msg.content
        
        # --- å¢å¼ºè§£æé€»è¾‘ ---
        # 1. å¦‚æœæ˜¯åˆ—è¡¨ (Multipart)ï¼Œæ‹¼æ¥
        if isinstance(content, list):
             content = " ".join([str(c) for c in content])
        
        # 2. å¦‚æœæ˜¯å­—å…¸ (æˆ–ç±»ä¼¼ç»“æ„)ï¼Œå°è¯•æå– text
        if isinstance(content, dict):
            content = content.get('text', str(content))
            
        # 3. å¦‚æœæ˜¯å­—ç¬¦ä¸²ä½†çœ‹èµ·æ¥åƒå­—å…¸ (Stringified Dict)
        content = str(content).strip()
        if content.startswith("{") and "text" in content:
            try:
                val = ast.literal_eval(content)
                if isinstance(val, dict) and 'text' in val:
                    content = val['text']
            except:
                pass # è§£æå¤±è´¥å°±ä¿ç•™åŸæ ·

        content = str(content).strip()

        # print(f"ğŸ¤– [Generator] AI å»ºè®®: {content}") 

        # --- è§£æé€»è¾‘ (ä¿æŒé²æ£’æ€§) ---
        if "|||" in content:
            index_part, reason = content.split("|||", 1)
            match = re.search(r'\d+', index_part)
            if match:
                return int(match.group()), reason.strip()
        
        # å…œåº•ï¼šå¦‚æœ AI ç›´æ¥è¯´äº†æ•°å­—å¼€å¤´
        match = re.search(r'^\d+', content)
        if match:
             return int(match.group()), f"ä¸ºæ‚¨æ¨èã€{candidates[int(match.group())]['name']}ã€‘"

        # å½»åº•æ— æ³•è§£æ
        return 0, f"è¯•è¯•è¿™é“ã€{candidates[0]['name']}ã€‘ï¼Œåº”è¯¥ä¸é”™ï¼"

    except Exception as e:
        print(f"âŒ [Generator] æŠ¥é”™: {e}")
        return 0, "ä¸ºæ‚¨æ¨èä»¥ä¸‹èœè°±ï¼š"

def generate_rag_answer(query: str, candidates: list) -> str:
    """
    ä¸ºæœç´¢ç»“æœåˆ—è¡¨ç”Ÿæˆä¸€æ®µ "å¨å¸ˆé¡¾é—®" é£æ ¼çš„ç»¼è¿°
    """
    if not llm:
        return "ğŸ¤– AI å¨å¸ˆæ­£åœ¨ä¼‘æ¯ï¼ˆæœªé…ç½® API Keyï¼‰ï¼Œè¯·ç›´æ¥æŸ¥çœ‹ä¸‹æ–¹èœè°±ã€‚"
        
    if not candidates:
        return "æŠ±æ­‰ï¼Œæ²¡æœ‰æ‰¾åˆ°ç›¸å…³èœè°±ï¼Œæˆ‘ä¹Ÿå¾ˆéš¾ä¸ºæ‚¨æä¾›å»ºè®®ã€‚"

    # 1. ç®€è¦æ„å»ºå€™é€‰ä¿¡æ¯
    candidates_summary = ""
    for i, doc in enumerate(candidates[:5]):
        candidates_summary += f"- {doc.get('name')} (æ ‡ç­¾: {doc.get('tags')})\n"

    system_prompt = """
    ä½ æ˜¯ä¸€ä½é«˜ç«¯å®¶åº­é¤å…çš„ä¸»å¨é¡¾é—®ã€‚
    ç”¨æˆ·çš„éœ€æ±‚å¯èƒ½åªæ˜¯å‡ ä¸ªé£Ÿæåã€‚ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®æœç´¢åˆ°çš„èœè°±åˆ—è¡¨ï¼Œç»™ç”¨æˆ·ä¸€æ®µ**ä¸“ä¸šã€ä¼˜é›…ä¸”å¾—ä½“**çš„å¼€åœºå»ºè®®ã€‚
    
    ã€æ¨èé€»è¾‘ã€‘ï¼š
    1.  **è¯­æ°”ä¸“ä¸š**ï¼šç¤¼è²Œã€æ¸©å’Œã€æœ‰è´¨æ„Ÿï¼ˆä¾‹å¦‚ï¼š"ä¸ºæ‚¨ç²¾é€‰äº†ä»¥ä¸‹å‡ é“ä½³è‚´..."ï¼‰ã€‚æ‹’ç»è°ƒä¾ƒæˆ–è¿‡åº¦çƒ­æƒ…ã€‚
    2.  **æ€»ç»“äº®ç‚¹**ï¼šæ¦‚æ‹¬èœå“ç‰¹è‰²ï¼Œä½“ç°çƒ¹é¥ªçš„è‰ºæœ¯æ„Ÿã€‚
    3.  **ç»™å‡ºå»ºè®®**ï¼šç®€è¦æåŠé£Ÿææ­é…æˆ–é£å‘³ç‰¹ç‚¹ã€‚
    4.  **å¹½é»˜ä¸äº’åŠ¨ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰**ï¼š
        - **å¿…é¡»æ£€æŸ¥**ï¼šæ— è®ºæ˜¯å¦æœåˆ°äº†èœè°±ï¼Œå…ˆæ£€æŸ¥ç”¨æˆ·çš„è¾“å…¥é‡Œæœ‰æ²¡æœ‰**å¥‡æ€ªã€ç¦»è°±æˆ–è°ƒä¾ƒ**çš„è¯ï¼ˆå¦‚â€œå±â€ã€â€œæ¯’è¯â€ã€â€œæ··å‡åœŸâ€ç­‰ï¼‰ã€‚
        - **æ··åˆè¾“å…¥å¤„ç†**ï¼šå¦‚æœç”¨æˆ·è¾“å…¥äº†â€œå·§å…‹åŠ›å’Œå±â€ï¼Œè™½ç„¶æœ‰å·§å…‹åŠ›èœè°±ï¼Œä½†ä½ **å¿…é¡»**å…ˆåæ§½â€œå±â€è¿™ä¸ªç¦»è°±çš„é£Ÿæï¼Œç„¶åå†æ¨èå·§å…‹åŠ›ï¼
        - **ä¾‹å­**ï¼šâ€œå·§å…‹åŠ›æˆ‘æ‡‚ï¼Œä½†â€˜å±â€™æ˜¯ä»€ä¹ˆé»‘æš—æ–™ç†ï¼ŸğŸ˜± ä¸ºäº†æ‚¨çš„ç”Ÿå‘½å®‰å…¨ï¼Œæˆ‘è¿˜æ˜¯åªç»™æ‚¨æ¨èæ­£å¸¸çš„ã€å·§å…‹åŠ›åšã€‘æ³•å§...â€
        - **æ‹’ç»æ— è§†**ï¼šç»å¯¹ä¸èƒ½å‡è£…æ²¡çœ‹è§ç¦»è°±è¯åªå›ç­”æ­£å¸¸çš„ï¼Œé‚£æ ·å¤ªå‘†æ¿äº†ï¼
    5.  **å½¢å¼è¦æ±‚**ï¼šä¸¥ç¦ä½¿ç”¨ Emoji è¡¨æƒ…ç¬¦å·ã€‚å­—æ•°æ§åˆ¶åœ¨ 100 å­—ä»¥å†…ã€‚
    
    """

    
    user_prompt = f"""
    ç”¨æˆ·æƒ³åƒ/æœ‰çš„é£Ÿæï¼šã€{query}ã€‘
    æœç´¢åˆ°çš„èœè°±ï¼š
    {candidates_summary}

    è¯·ç»™ç”¨æˆ·ä¸€æ®µç®€çŸ­çš„é«˜çº§æ„Ÿæ¨èè¯­ï¼š
    """

    try:
        messages = [
            ("system", system_prompt),
            ("human", user_prompt),
        ]
        
        response = safe_invoke(messages)
        content = response.content
        
         # --- å¢å¼ºè§£æé€»è¾‘ ---
        if isinstance(content, list):
             content = " ".join([str(c) for c in content])
             
        if isinstance(content, dict):
            content = content.get('text', str(content))

        content = str(content).strip()
        
        # å¤„ç† Stringified Dict (ä¾‹å¦‚ SiliconFlow/DeepSeek å¶å°”è¿”å›çš„æ ¼å¼)
        if content.startswith("{") and "text" in content:
            try:
                import ast
                val = ast.literal_eval(content)
                if isinstance(val, dict) and 'text' in val:
                    content = val['text']
            except:
                pass

        print(f"âœ… AI å“åº”å†…å®¹: {content[:50]}...")
        return content
            
    except Exception as e:
        print(f"âŒ [Generator] Summary æŠ¥é”™: {e}")
        return f"åŸºäºæ‚¨çš„é£Ÿæåå¥½ï¼Œæˆ‘ä¸ºæ‚¨ç”„é€‰äº†ä»¥ä¸‹å‡ é“å€¼å¾—å°è¯•çš„ç¾å‘³ä½³è‚´ã€‚"
